{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TBird.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbirdss/new/blob/test-py/TBirdLast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeixY-MX6Hkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-WKJkCRBSUC",
        "colab_type": "code",
        "outputId": "ad7b2d5d-207e-4414-c81a-5e45ca8fd9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#Using Bottleneck Features for Multi-Class Classification in Keras\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "#import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPKELQ59CXk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of our images when loading.\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "top_model_weights_path = '/content/drive/My Drive/TBird/DOCS/DOCMODEL/MODEL.h5'\n",
        "train_data_dir = '/content/drive/My Drive/TBird/DOCS/train'\n",
        "validation_data_dir = '/content/drive/My Drive/TBird/DOCS/validation'\n",
        "\n",
        "# number of epochs to train top model\n",
        "epochs = 50\n",
        "# batch size used by flow_from_directory and predict_generator\n",
        "batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCeCiBKsEVAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_generator(root_path):\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        root_path,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    # Comment out print statement to protect privacy\n",
        "    #generator.filenames contains all the filenames\n",
        "    #print('total number of samples = {0}'.format(len(generator.filenames)))\n",
        "    \n",
        "    # generator.class_indices is the map/dictionary for the class-names and their indexes\n",
        "    #print('number of categories= {0}'.format(len(generator.class_indices)))\n",
        "    \n",
        "    #print('\\ncategory vs. index mapping:')\n",
        "    #print(generator.class_indices)\n",
        "    \n",
        "    return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hwKdS2UEZHk",
        "colab_type": "code",
        "outputId": "9eedb5fb-24ae-410b-e6c0-971d43a3ae82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_generator = create_generator(train_data_dir)\n",
        "validation_generator = create_generator(validation_data_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7346 images belonging to 12 classes.\n",
            "Found 1843 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjJ0SVa-E0cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_bottlebeck_features(train_generator, validation_generator):\n",
        "    \n",
        "    # build the VGG16 network, use the weights trained on imagenet data\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "\n",
        "    nb_train_samples = len(train_generator.filenames)\n",
        "    num_classes = len(train_generator.class_indices)\n",
        "\n",
        "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        train_generator, predict_size_train)\n",
        "\n",
        "    np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
        "\n",
        "   \n",
        "    nb_validation_samples = len(validation_generator.filenames)\n",
        "\n",
        "    predict_size_validation = int(\n",
        "        math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        validation_generator, predict_size_validation)\n",
        "\n",
        "    np.save('bottleneck_features_validation.npy',\n",
        "            bottleneck_features_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkFT8rNDE9HK",
        "colab_type": "code",
        "outputId": "563437c6-8f42-4eda-de40-5b90971fb43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "save_bottlebeck_features(train_generator, validation_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e67c67946e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_bottlebeck_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-9deb877f5d35>\u001b[0m in \u001b[0;36msave_bottlebeck_features\u001b[0;34m(train_generator, validation_generator)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# build the VGG16 network, use the weights trained on imagenet data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN9mki7OI9ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_FC_model():\n",
        "    datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
        "    generator_top = datagen_top.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_train_samples = len(generator_top.filenames)\n",
        "    num_classes = len(generator_top.class_indices)\n",
        "\n",
        "    # save the class indices to use use later in predictions\n",
        "    np.save('class_indices.npy', generator_top.class_indices)\n",
        "\n",
        "    # load the bottleneck features saved earlier\n",
        "    train_data = np.load('bottleneck_features_train.npy')\n",
        "\n",
        "    # get the class lebels for the training data, in the original order\n",
        "    train_labels = generator_top.classes\n",
        "\n",
        "    # https://github.com/fchollet/keras/issues/3467\n",
        "    # convert the training labels to categorical vectors\n",
        "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "\n",
        "    generator_top = datagen_top.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_validation_samples = len(generator_top.filenames)\n",
        "\n",
        "    validation_data = np.load('bottleneck_features_validation.npy')\n",
        "\n",
        "    validation_labels = generator_top.classes\n",
        "    validation_labels = to_categorical(\n",
        "        validation_labels, num_classes=num_classes)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #model.add(Dense(num_classes, activation='sigmoid'))  # to get class prediction\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))   # to get probability prediction\n",
        "    \n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_data, train_labels,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(validation_data, validation_labels))\n",
        "\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "    (eval_loss, eval_accuracy) = model.evaluate(\n",
        "        validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "    print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "\n",
        "    plt.figure(1)\n",
        "\n",
        "    # summarize history for accuracy\n",
        "\n",
        "    plt.subplot(211)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    # summarize history for loss\n",
        "\n",
        "    plt.subplot(212)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHdHr_jBI9qf",
        "colab_type": "code",
        "outputId": "c84bad93-c9ae-4ed8-dc65-2e9c02eb9975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_FC_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7346 images belonging to 12 classes.\n",
            "Found 1843 images belonging to 12 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7346 samples, validate on 1843 samples\n",
            "Epoch 1/50\n",
            "7346/7346 [==============================] - 6s 821us/step - loss: 0.6302 - acc: 0.8801 - val_loss: 0.0549 - val_acc: 0.9837\n",
            "Epoch 2/50\n",
            "7346/7346 [==============================] - 5s 725us/step - loss: 0.1432 - acc: 0.9645 - val_loss: 0.0270 - val_acc: 0.9940\n",
            "Epoch 3/50\n",
            "7346/7346 [==============================] - 5s 717us/step - loss: 0.1043 - acc: 0.9751 - val_loss: 0.0242 - val_acc: 0.9951\n",
            "Epoch 4/50\n",
            "7346/7346 [==============================] - 5s 728us/step - loss: 0.1045 - acc: 0.9792 - val_loss: 0.0223 - val_acc: 0.9957\n",
            "Epoch 5/50\n",
            "7346/7346 [==============================] - 5s 726us/step - loss: 0.0810 - acc: 0.9830 - val_loss: 0.0256 - val_acc: 0.9946\n",
            "Epoch 6/50\n",
            "7346/7346 [==============================] - 5s 713us/step - loss: 0.0636 - acc: 0.9853 - val_loss: 0.0223 - val_acc: 0.9957\n",
            "Epoch 7/50\n",
            "7346/7346 [==============================] - 5s 723us/step - loss: 0.0642 - acc: 0.9872 - val_loss: 0.0445 - val_acc: 0.9913\n",
            "Epoch 8/50\n",
            "7346/7346 [==============================] - 5s 718us/step - loss: 0.0598 - acc: 0.9891 - val_loss: 0.0222 - val_acc: 0.9967\n",
            "Epoch 9/50\n",
            "7346/7346 [==============================] - 5s 711us/step - loss: 0.0587 - acc: 0.9887 - val_loss: 0.0262 - val_acc: 0.9946\n",
            "Epoch 10/50\n",
            "7346/7346 [==============================] - 5s 724us/step - loss: 0.0594 - acc: 0.9905 - val_loss: 0.0232 - val_acc: 0.9967\n",
            "Epoch 11/50\n",
            "7346/7346 [==============================] - 5s 729us/step - loss: 0.0524 - acc: 0.9902 - val_loss: 0.0337 - val_acc: 0.9957\n",
            "Epoch 12/50\n",
            "7346/7346 [==============================] - 5s 720us/step - loss: 0.0403 - acc: 0.9925 - val_loss: 0.0215 - val_acc: 0.9962\n",
            "Epoch 13/50\n",
            "7346/7346 [==============================] - 5s 730us/step - loss: 0.0372 - acc: 0.9935 - val_loss: 0.0143 - val_acc: 0.9962\n",
            "Epoch 14/50\n",
            "7346/7346 [==============================] - 5s 723us/step - loss: 0.0351 - acc: 0.9936 - val_loss: 0.0289 - val_acc: 0.9957\n",
            "Epoch 15/50\n",
            "7346/7346 [==============================] - 5s 712us/step - loss: 0.0365 - acc: 0.9922 - val_loss: 0.0330 - val_acc: 0.9957\n",
            "Epoch 16/50\n",
            "7346/7346 [==============================] - 5s 720us/step - loss: 0.0347 - acc: 0.9936 - val_loss: 0.0314 - val_acc: 0.9967\n",
            "Epoch 17/50\n",
            "7346/7346 [==============================] - 5s 714us/step - loss: 0.0392 - acc: 0.9921 - val_loss: 0.0342 - val_acc: 0.9962\n",
            "Epoch 18/50\n",
            "7346/7346 [==============================] - 5s 707us/step - loss: 0.0399 - acc: 0.9943 - val_loss: 0.0255 - val_acc: 0.9962\n",
            "Epoch 19/50\n",
            "7346/7346 [==============================] - 5s 713us/step - loss: 0.0384 - acc: 0.9939 - val_loss: 0.0216 - val_acc: 0.9973\n",
            "Epoch 20/50\n",
            "7346/7346 [==============================] - 5s 718us/step - loss: 0.0389 - acc: 0.9935 - val_loss: 0.0172 - val_acc: 0.9962\n",
            "Epoch 21/50\n",
            "7346/7346 [==============================] - 5s 723us/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0498 - val_acc: 0.9946\n",
            "Epoch 22/50\n",
            "7346/7346 [==============================] - 5s 731us/step - loss: 0.0383 - acc: 0.9941 - val_loss: 0.0463 - val_acc: 0.9940\n",
            "Epoch 23/50\n",
            "7346/7346 [==============================] - 5s 715us/step - loss: 0.0348 - acc: 0.9951 - val_loss: 0.0434 - val_acc: 0.9957\n",
            "Epoch 24/50\n",
            "7346/7346 [==============================] - 5s 718us/step - loss: 0.0274 - acc: 0.9948 - val_loss: 0.0228 - val_acc: 0.9967\n",
            "Epoch 25/50\n",
            "7346/7346 [==============================] - 5s 748us/step - loss: 0.0291 - acc: 0.9952 - val_loss: 0.0198 - val_acc: 0.9957\n",
            "Epoch 26/50\n",
            "7346/7346 [==============================] - 5s 744us/step - loss: 0.0349 - acc: 0.9943 - val_loss: 0.0254 - val_acc: 0.9962\n",
            "Epoch 27/50\n",
            "7346/7346 [==============================] - 6s 755us/step - loss: 0.0260 - acc: 0.9961 - val_loss: 0.0310 - val_acc: 0.9957\n",
            "Epoch 28/50\n",
            "7346/7346 [==============================] - 5s 723us/step - loss: 0.0238 - acc: 0.9958 - val_loss: 0.0408 - val_acc: 0.9957\n",
            "Epoch 29/50\n",
            "7346/7346 [==============================] - 5s 729us/step - loss: 0.0253 - acc: 0.9955 - val_loss: 0.0607 - val_acc: 0.9940\n",
            "Epoch 30/50\n",
            "7346/7346 [==============================] - 5s 724us/step - loss: 0.0193 - acc: 0.9973 - val_loss: 0.0216 - val_acc: 0.9973\n",
            "Epoch 31/50\n",
            "7346/7346 [==============================] - 5s 722us/step - loss: 0.0211 - acc: 0.9965 - val_loss: 0.0311 - val_acc: 0.9957\n",
            "Epoch 32/50\n",
            "7346/7346 [==============================] - 5s 728us/step - loss: 0.0260 - acc: 0.9955 - val_loss: 0.0091 - val_acc: 0.9989\n",
            "Epoch 33/50\n",
            "7346/7346 [==============================] - 5s 729us/step - loss: 0.0289 - acc: 0.9961 - val_loss: 0.0188 - val_acc: 0.9967\n",
            "Epoch 34/50\n",
            "7346/7346 [==============================] - 5s 715us/step - loss: 0.0154 - acc: 0.9973 - val_loss: 0.0361 - val_acc: 0.9967\n",
            "Epoch 35/50\n",
            "7346/7346 [==============================] - 5s 734us/step - loss: 0.0324 - acc: 0.9951 - val_loss: 0.0227 - val_acc: 0.9973\n",
            "Epoch 36/50\n",
            "7346/7346 [==============================] - 5s 712us/step - loss: 0.0253 - acc: 0.9967 - val_loss: 0.0097 - val_acc: 0.9989\n",
            "Epoch 37/50\n",
            "7346/7346 [==============================] - 5s 719us/step - loss: 0.0302 - acc: 0.9951 - val_loss: 0.0207 - val_acc: 0.9973\n",
            "Epoch 38/50\n",
            "7346/7346 [==============================] - 5s 716us/step - loss: 0.0150 - acc: 0.9975 - val_loss: 0.0086 - val_acc: 0.9973\n",
            "Epoch 39/50\n",
            "7346/7346 [==============================] - 5s 728us/step - loss: 0.0275 - acc: 0.9961 - val_loss: 0.0200 - val_acc: 0.9984\n",
            "Epoch 40/50\n",
            "7346/7346 [==============================] - 5s 728us/step - loss: 0.0294 - acc: 0.9963 - val_loss: 0.0191 - val_acc: 0.9978\n",
            "Epoch 41/50\n",
            "7346/7346 [==============================] - 5s 719us/step - loss: 0.0128 - acc: 0.9981 - val_loss: 0.0088 - val_acc: 0.9995\n",
            "Epoch 42/50\n",
            "7346/7346 [==============================] - 5s 736us/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0197 - val_acc: 0.9967\n",
            "Epoch 43/50\n",
            "7346/7346 [==============================] - 6s 752us/step - loss: 0.0143 - acc: 0.9977 - val_loss: 0.0148 - val_acc: 0.9984\n",
            "Epoch 44/50\n",
            "7346/7346 [==============================] - 6s 753us/step - loss: 0.0216 - acc: 0.9963 - val_loss: 0.0074 - val_acc: 0.9995\n",
            "Epoch 45/50\n",
            "7346/7346 [==============================] - 5s 729us/step - loss: 0.0161 - acc: 0.9970 - val_loss: 0.0193 - val_acc: 0.9978\n",
            "Epoch 46/50\n",
            "7346/7346 [==============================] - 5s 720us/step - loss: 0.0157 - acc: 0.9980 - val_loss: 0.0170 - val_acc: 0.9984\n",
            "Epoch 47/50\n",
            "7346/7346 [==============================] - 5s 720us/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0140 - val_acc: 0.9978\n",
            "Epoch 48/50\n",
            "7346/7346 [==============================] - 5s 741us/step - loss: 0.0152 - acc: 0.9978 - val_loss: 0.0093 - val_acc: 0.9989\n",
            "Epoch 49/50\n",
            "7346/7346 [==============================] - 5s 709us/step - loss: 0.0202 - acc: 0.9978 - val_loss: 0.0202 - val_acc: 0.9973\n",
            "Epoch 50/50\n",
            "7346/7346 [==============================] - 5s 720us/step - loss: 0.0200 - acc: 0.9970 - val_loss: 0.0105 - val_acc: 0.9978\n",
            "1843/1843 [==============================] - 0s 187us/step\n",
            "[INFO] accuracy: 99.78%\n",
            "[INFO] Loss: 0.010475058314116855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTp4gnHPO5eQJwjnnXE7/AxVpCgc2KyZiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lifT5-QVJg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "05f24ac5-e184-49ad-aa93-019ac185a0ae"
      },
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import os\n",
        "import tensorflow\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "#import numpy as np\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import cv2\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |                           | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |                       | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |                   | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |               | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |          | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |      | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |  | 71kB 6.8MB/s eta 0:00:01\r\u001b[K     || 81kB 4.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61085 sha256=f64b3e57b6756c43805eeca2b02379118a76f49ed1f87b7bbcfd6afbb5248d9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRyUaGXPWNt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_img(img):\n",
        "    img = img.resize((150, 150))  # resize the image\n",
        "    img = np.array(img)\n",
        "    #img = img / np.max(img).astype(float)\n",
        "    img = np.reshape(img, [1, 150, 150, 3])\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7feX7WgI9fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(image_path):\n",
        "    # load the class_indices saved in the earlier step\n",
        "    class_dictionary = np.load('class_indices.npy',allow_pickle=True).item()\n",
        "\n",
        "    num_classes = len(class_dictionary)\n",
        "\n",
        "    #load and pre-process the image\n",
        "    #orig = cv2.imread(image_path)\n",
        "    print(\"[INFO] loading and preprocessing image...\")\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    # Rescale the image, this is important, otherwise the predictions will be '0'\n",
        "    # This is because ImageDataGenerator set rescale=1. / 255, \n",
        "    # which means all data is re-scaled from a [0 - 255] range to [0 - 1.0]\n",
        "    image = image / 255\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    \n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "    # get the bottleneck prediction from the pre-trained VGG16 model\n",
        "    bottleneck_prediction = model.predict(image)\n",
        "    #print(bottleneck_prediction)\n",
        "\n",
        "    # build top FC model block\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=bottleneck_prediction.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    #model.add(Dense(num_classes, activation='sigmoid'))  # to get class prediction\n",
        "    model.add(Dense(num_classes, activation='softmax'))   # to get probability prediction\n",
        "    \n",
        "    model.load_weights(top_model_weights_path)\n",
        "\n",
        "    # use the bottleneck prediction on the FC model to get the final classification\n",
        "    class_predicted = model.predict_classes(bottleneck_prediction)\n",
        "\n",
        "    #proba = model.predict_proba(bottleneck_prediction)\n",
        "    \n",
        "    output_y = model.predict(bottleneck_prediction)\n",
        "\n",
        "    inID = class_predicted[0]\n",
        "\n",
        "    inv_map = {v: k for k, v in class_dictionary.items()}\n",
        "\n",
        "    label = inv_map[inID]\n",
        "\n",
        "    # get the prediction label\n",
        "    print(\"Prediction: class ID: {}, Label: {}\".format(inID, label))\n",
        "    \n",
        "    #print(proba)\n",
        "    pos = -1\n",
        "    count = 0\n",
        "    maximum = max(output_y[0])\n",
        "    predict1 = {}\n",
        "    for i in range(len(output_y[0])):\n",
        "        predict1[inv_map[i]] = output_y[0][i]\n",
        "        if maximum == prediction[0][i]:\n",
        "          pos = i\n",
        "          count = count + 1\n",
        "        elif maximum * 0.222 < prediction[0][i]:\n",
        "          count = count + 1\n",
        "    if count > 1:\n",
        "        print(\"Not Found\")\n",
        "        writer.addBookmark(\"Not Found\",Page_No, parent=PARENT)\n",
        "    else:\n",
        "        print(CATEGORIES[pos])\n",
        "        writer.addBookmark(CATEGORIES[pos], Page_No, parent=CATEGORIT[pos])\n",
        "\n",
        "    print('sum of probability = {0}'.format(sum(output_y[0])))\n",
        "    \n",
        "    \n",
        "\n",
        "    # display the predictions with the image\n",
        "    '''\n",
        "    cv2.putText(orig, \"Predicted: {}\".format(label), (10, 30),\n",
        "                cv2.FONT_HERSHEY_PLAIN, 1.5, (43, 99, 255), 2)\n",
        "\n",
        "    cv2.imshow(\"Classification\", orig)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    '''\n",
        "    return output_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt5-0TBjWaiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Enter_Required_Data():\n",
        "\n",
        "    Message1 = \"Enter PDF Source Path (End with /,Example: C:/User/Admin/Documents/):\"\n",
        "    Message2 = \"Enter PDF name (Example: Henry.pdf)\"\n",
        "    print(Message1)\n",
        "    pdf_source = input()\n",
        "    print(Message2)\n",
        "    File_Name = input()\n",
        "    return File_Name, pdf_source"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50hs_XmTW8-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Pdf_data_Extractor(File_Name, pdf_source):\n",
        "\n",
        "    Png_conversion_Script = \"/content/drive/My Drive/Splitter\"\n",
        "    Pdf_Source_File_Name = pdf_source + File_Name\n",
        "\n",
        "    reader = PyPDF2.PdfFileReader(Pdf_Source_File_Name)\n",
        "    writer = PyPDF2.PdfFileWriter()\n",
        "\n",
        "    File_Name = File_Name.split('.')[0]\n",
        "    #os.mkdir(pdf_source+\"Temp\")\n",
        "    Total_Number_of_Pages = reader.getNumPages()\n",
        "    for Pg_No in range(0,Total_Number_of_Pages):\n",
        "        Temporary_Directory = pdf_source + \"Temp/\" + File_Name+str(Pg_No)\n",
        "        writer.addPage(reader.getPage(Pg_No))\n",
        "        Command = \"{} -f {} -l {} {} {}\".format(Png_conversion_Script, Pg_No+1, Pg_No+1, Pdf_Source_File_Name, Temporary_Directory)\n",
        "        #os.system(Command)\n",
        "        print(Command)\n",
        "    return writer,Total_Number_of_Pages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPAzpGQ_XNGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_And_Bookmark(writer,Total_Number_of_Pages, source_name, file_name):\n",
        "\n",
        "    CATEGORIES = os.listdir('/content/drive/My Drive/TBird/DOCS/train')\n",
        "    CATEGORIT=[]\n",
        "    for g in range(0, int(13)):\n",
        "        if (g<12):\n",
        "            CATEG =writer.addBookmark(CATEGORIES[g], 0, color=(1,0,0), bold=True)\n",
        "            CATEGORIT.append(CATEG)\n",
        "        else:\n",
        "            PARENT = writer.addBookmark(\"MISC DOCS\", 0,color=(0,0,0), bold=True)\n",
        "\n",
        "    List_of_images = os.listdir(source_name+\"/Temp/\")\n",
        "    List_of_images.sort()\n",
        "    b=0\n",
        "    for Page_No, Img in enumerate(List_of_images):\n",
        "        ###############################################\n",
        "        \"\"\"Prediction Code Here returns pos\"\"\"\n",
        "        b=b+1\n",
        "        print(b)\n",
        "\n",
        "        test_image = Image.open(source_name+\"/Temp/\"+Img)\n",
        "        test_imag =source_name+\"/Temp/\"+Img\n",
        "        print(test_imag)\n",
        "        #test_image = process_img(test_image)\n",
        "        prediction = predict(test_imag)\n",
        "        print(prediction, Img)\n",
        "        pos = -1\n",
        "        count = 0\n",
        "        maximum = max(prediction[0])\n",
        "\n",
        "#        for i in range(0, len(prediction[0])):\n",
        "#            if maximum == prediction[0][i]:\n",
        "#                pos = i\n",
        "#                count = count + 1\n",
        "#            elif maximum * 0.222 < prediction[0][i]:\n",
        "#                count = count + 1\n",
        "#        if count > 1:\n",
        "#            print(\"Not Found\")\n",
        "\n",
        "#            writer.addBookmark(\"Not Found\",Page_No, parent=PARENT)\n",
        "\n",
        "#        else:\n",
        "#            print(CATEGORIES[pos])\n",
        "#            writer.addBookmark(CATEGORIES[pos], Page_No, parent=CATEGORIT[pos])\n",
        "\n",
        "    sys.setrecursionlimit(2000)\n",
        "    with open(source_name+file_name.split(\".\")[0]+\"ReBookmarked.pdf\",\"wb\") as out:\n",
        "        writer.write(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td3jxLdQck-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Remove_Temp_Files(pdf_source):\n",
        "   for x in os.listdir(pdf_source+\"Temp\"):\n",
        "       os.remove(pdf_source+\"Temp/\"+x)\n",
        "   os.removedirs(pdf_source+\"Temp\")\n",
        "    #os.removedirs(pdf_source+\"Temp\")\n",
        "   print(\"Removed Temp Folder\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2iWYJ-cuzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    File_Name, pdf_source = Enter_Required_Data()\n",
        "    Source_Name = pdf_source + File_Name\n",
        "\n",
        "    writer, Total_Number_of_Pages = Pdf_data_Extractor(File_Name, pdf_source)\n",
        "\n",
        "    prediction_And_Bookmark(writer, Total_Number_of_Pages, pdf_source,File_Name)\n",
        "\n",
        "    #Remove_Temp_Files(pdf_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgU-SMZpc34q",
        "colab_type": "code",
        "outputId": "e4d3cfc6-b5cb-4b2f-900d-fff9af2ade30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter PDF Source Path (End with /,Example: C:/User/Admin/Documents/):\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpT1ryw4KRMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the path to your test image below\n",
        "image_path = './data/Document_PNG/validation/Bank Statement/Chase-bank-statement-2.png'\n",
        "predict(image_path)\n",
        "\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmMSbrk3Fywa",
        "colab_type": "code",
        "outputId": "b9bcfc28-d057-4001-91c4-20b957279a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "# add the path to your test image below\n",
        "image_path = '/content/drive/My Drive/TBird/DOCS/train/1003/BALDWIN1-000002.png'\n",
        "predict(image_path)\n",
        "\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading and preprocessing image...\n",
            "[[[[0.         0.         0.         ... 0.         0.5832435\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.24042511\n",
            "    0.        ]\n",
            "   [0.         0.         0.03893572 ... 0.         0.31317526\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.26427186\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.25254652\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.57497525\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.69911414\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.5438157\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.48348218\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.6424187\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.65076196\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.8694168\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.6548303\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.45532364\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.46964157\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.45366272\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.5675098\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.8813515\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.51180464\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.47698963\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.5571052\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.5338672\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.5397569\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.5739215\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.32918614\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.47241253\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.54114985\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.52476656\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.5402049\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.63141793\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.6990852\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.4535665\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.48111665\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.6265768\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.63617796\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.7073651\n",
            "    0.        ]]]]\n",
            "1/1 [==============================] - 0s\n",
            "Prediction: class ID: 0, Label: 1003\n",
            "{'1003': 1.0, '1003_ADDENDUM': 0.0, '1008': 1.0102087e-33, '4506_-_T': 0.0, 'CD': 0.0, 'FACTS': 4.041669e-34, 'FAIR_CREDIT_REPORTING_ACT': 0.0, 'FLOOD_INSURANCE_DECLARATION_PAGE': 7.00147e-32, 'MORTGAGE_FRAUD': 0.0, 'NOTICE_TO_HOMEOWNER': 0.0, 'SSA_-_89': 0.0, 'W_-_9': 2.0337948e-38}\n",
            "sum of probability = 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5832435 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.24042511, 0.        ],\n",
              "         [0.        , 0.        , 0.03893572, ..., 0.        ,\n",
              "          0.31317526, 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.26427186, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.25254652, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.57497525, 0.        ]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.69911414, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5438157 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.48348218, 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.6424187 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.65076196, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.8694168 , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.6548303 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.45532364, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.46964157, 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.45366272, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5675098 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.8813515 , 0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.51180464, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.47698963, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5571052 , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5338672 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5397569 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5739215 , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.32918614, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.47241253, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.54114985, 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.52476656, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.5402049 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.63141793, 0.        ]],\n",
              "\n",
              "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.6990852 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.4535665 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.48111665, 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.6265768 , 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.63617796, 0.        ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "          0.7073651 , 0.        ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-EONCSOGlaO",
        "colab_type": "code",
        "outputId": "0f5042cf-b359-4c45-c552-4b980d5d2cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "!pip install tensorflow==1.4.0."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.4.0.\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9f/be0165c6eefd841e6928e54d3d083fa174f92d640fdc52f73a33dc9c54d1/tensorflow-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (41.2MB)\n",
            "\u001b[K     || 41.2MB 209kB/s \n",
            "\u001b[?25hCollecting enum34>=1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0.) (0.33.6)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0.) (1.17.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0.) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0.) (3.10.0)\n",
            "Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/9f/5845c18f9df5e7ea638ecf3a272238f0e7671e454faa396b5188c6e6fc0a/tensorflow_tensorboard-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     || 1.7MB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4.0.) (41.6.0)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     || 890kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0.) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0.) (0.16.0)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107221 sha256=224c9d9ca4602f2000a7a0ef7d2b3f4f7e457bc5f3c8a6e5469a1ad1cc963a30\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: enum34, html5lib, bleach, tensorflow-tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}