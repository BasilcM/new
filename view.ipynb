{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "view.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbirdss/new/blob/master/view.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZmxdSoABxvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-WKJkCRBSUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Bottleneck Features for Multi-Class Classification in Keras\n",
        "#!pip install voila-gridstack\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "#import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPKELQ59CXk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of our images when loading.\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "top_model_weights_path = '/content/drive/My Drive/TBird/DOCS/DOCMODEL/MODEL.h5'\n",
        "train_data_dir = '/content/drive/My Drive/TBird/DOCS/train'\n",
        "validation_data_dir = '/content/drive/My Drive/TBird/DOCS/validation'\n",
        "\n",
        "# number of epochs to train top model\n",
        "epochs = 50\n",
        "# batch size used by flow_from_directory and predict_generator\n",
        "batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCeCiBKsEVAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_generator(root_path):\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        root_path,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    # Comment out print statement to protect privacy\n",
        "    #generator.filenames contains all the filenames\n",
        "    #print('total number of samples = {0}'.format(len(generator.filenames)))\n",
        "    \n",
        "    # generator.class_indices is the map/dictionary for the class-names and their indexes\n",
        "    #print('number of categories= {0}'.format(len(generator.class_indices)))\n",
        "    \n",
        "    #print('\\ncategory vs. index mapping:')\n",
        "    #print(generator.class_indices)\n",
        "    \n",
        "    return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hwKdS2UEZHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = create_generator(train_data_dir)\n",
        "validation_generator = create_generator(validation_data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjJ0SVa-E0cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_bottlebeck_features(train_generator, validation_generator):\n",
        "    \n",
        "    # build the VGG16 network, use the weights trained on imagenet data\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "\n",
        "    nb_train_samples = len(train_generator.filenames)\n",
        "    num_classes = len(train_generator.class_indices)\n",
        "\n",
        "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        train_generator, predict_size_train)\n",
        "\n",
        "    np.save('/content/drive/My Drive/TBird/DOCS/DOCMODEL/bottleneck_features_train.npy', bottleneck_features_train)\n",
        "\n",
        "   \n",
        "    nb_validation_samples = len(validation_generator.filenames)\n",
        "\n",
        "    predict_size_validation = int(\n",
        "        math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        validation_generator, predict_size_validation)\n",
        "\n",
        "    np.save('/content/drive/My Drive/TBird/DOCS/DOCMODEL/bottleneck_features_validation.npy',\n",
        "            bottleneck_features_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6ijMVKKfdQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "for i in tqdm(range(int(1))):\n",
        "  save_bottlebeck_features(train_generator, validation_generator)\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkFT8rNDE9HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_bottlebeck_features(train_generator, validation_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN9mki7OI9ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_FC_model():\n",
        "    datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
        "    generator_top = datagen_top.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_train_samples = len(generator_top.filenames)\n",
        "    num_classes = len(generator_top.class_indices)\n",
        "\n",
        "    # save the class indices to use use later in predictions\n",
        "    np.save('/content/drive/My Drive/TBird/DOCS/DOCMODEL/class_indices.npy', generator_top.class_indices)\n",
        "\n",
        "    # load the bottleneck features saved earlier\n",
        "    train_data = np.load('/content/drive/My Drive/TBird/DOCS/DOCMODEL/bottleneck_features_train.npy')\n",
        "\n",
        "    # get the class lebels for the training data, in the original order\n",
        "    train_labels = generator_top.classes\n",
        "\n",
        "    # https://github.com/fchollet/keras/issues/3467\n",
        "    # convert the training labels to categorical vectors\n",
        "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "\n",
        "    generator_top = datagen_top.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_validation_samples = len(generator_top.filenames)\n",
        "\n",
        "    validation_data = np.load('/content/drive/My Drive/TBird/DOCS/DOCMODEL/bottleneck_features_validation.npy')\n",
        "\n",
        "    validation_labels = generator_top.classes\n",
        "    validation_labels = to_categorical(\n",
        "        validation_labels, num_classes=num_classes)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #model.add(Dense(num_classes, activation='sigmoid'))  # to get class prediction\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))   # to get probability prediction\n",
        "    \n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_data, train_labels,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(validation_data, validation_labels))\n",
        "\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "    (eval_loss, eval_accuracy) = model.evaluate(\n",
        "        validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "    print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "\n",
        "    plt.figure(1)\n",
        "\n",
        "    # summarize history for accuracy\n",
        "\n",
        "    plt.subplot(211)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    # summarize history for loss\n",
        "\n",
        "    plt.subplot(212)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "########################################################\n",
        "    #%load_ext tensorboard\n",
        "    #import datetime\n",
        "\n",
        "    #!rm -rf ./logs/\n",
        "\n",
        "    #lo\n",
        "\n",
        "    train_data.shape\n",
        "    len(train_labels)\n",
        "\n",
        "    train_labels\n",
        "\n",
        "    validation_data.shape\n",
        "    len(validation_labels)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(train_data[0])\n",
        "    plt.colorbar()\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    train_data.shape\n",
        "    len(train_labels)\n",
        "\n",
        "    train_labels\n",
        "\n",
        "    validation_data.shape\n",
        "    len(validation_labels)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(train_data[0])\n",
        "    plt.colorbar()\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    import os\n",
        "    import sys\n",
        "    class_nm=os.dir(train_data_dir)\n",
        "    plt.figure(figsize(10,10))\n",
        "    for i in range(12):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(train_data[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_nm[train_labels[i]])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpLnXiNgupDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    train_data.shape\n",
        "    len(train_labels)\n",
        "\n",
        "    train_labels\n",
        "\n",
        "    validation_data.shape\n",
        "    len(validation_labels)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(train_images[0])\n",
        "    plt.colorbar()\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    train_data.shape\n",
        "    len(train_labels)\n",
        "\n",
        "    train_labels\n",
        "\n",
        "    validation_data.shape\n",
        "    len(validation_labels)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(train_images[0])\n",
        "    plt.colorbar()\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    import os\n",
        "    import sys\n",
        "    class_nm=os.dir(train_data_dir)\n",
        "    plt.figure(figsize(10,10))\n",
        "    for i in range(12):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_nm[train_labels[i]])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKGkEDS6BpMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "class_nm=os.dir(train_data_dir)\n",
        "plt.figure(figsize(10,10))\n",
        "for i in range(12)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_nm[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHdHr_jBI9qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_FC_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av_m9ELWHEq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lifT5-QVJg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import os\n",
        "import tensorflow\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "#import numpy as np\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRyUaGXPWNt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_img(img):\n",
        "    img = img.resize((150, 150))  # resize the image\n",
        "    img = np.array(img)\n",
        "    #img = img / np.max(img).astype(float)\n",
        "    img = np.reshape(img, [1, 150, 150, 3])\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7feX7WgI9fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(image_path):\n",
        "    # load the class_indices saved in the earlier step\n",
        "    class_dictionary = np.load('/content/drive/My Drive/TBird/DOCS/DOCMODEL/class_indices.npy',allow_pickle=True).item()\n",
        "\n",
        "    num_classes = len(class_dictionary)\n",
        "\n",
        "    #load and pre-process the image\n",
        "    #orig = cv2.imread(image_path)\n",
        "    print(\"[INFO] loading and preprocessing image...\")\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    # Rescale the image, this is important, otherwise the predictions will be '0'\n",
        "    # This is because ImageDataGenerator set rescale=1. / 255, \n",
        "    # which means all data is re-scaled from a [0 - 255] range to [0 - 1.0]\n",
        "    image = image / 255\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    \n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "    # get the bottleneck prediction from the pre-trained VGG16 model\n",
        "    bottleneck_prediction = model.predict(image)\n",
        "    #print(bottleneck_prediction)\n",
        "\n",
        "    # build top FC model block\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=bottleneck_prediction.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    #model.add(Dense(num_classes, activation='sigmoid'))  # to get class prediction\n",
        "    model.add(Dense(num_classes, activation='softmax'))   # to get probability prediction\n",
        "    \n",
        "    model.load_weights(top_model_weights_path)\n",
        "\n",
        "    # use the bottleneck prediction on the FC model to get the final classification\n",
        "    class_predicted = model.predict_classes(bottleneck_prediction)\n",
        "\n",
        "    #proba = model.predict_proba(bottleneck_prediction)\n",
        "    \n",
        "    output_y = model.predict(bottleneck_prediction)\n",
        "    #print('**************',output_y,'**************')\n",
        "    inID = class_predicted[0]\n",
        "\n",
        "    inv_map = {v: k for k, v in class_dictionary.items()}\n",
        "\n",
        "    label = inv_map[inID]\n",
        "    # get the prediction label\n",
        "    print(\"Prediction: class ID: {}, Label: {}\".format(inID, label))\n",
        "    \n",
        "    #print(proba)\n",
        "    \n",
        "    predict1 = {}\n",
        "    for i in range(len(output_y[0])):\n",
        "        predict1[inv_map[i]] = output_y[0][i]\n",
        "\n",
        "    print('sum of probability = {0}'.format(sum(output_y[0])))\n",
        "    \n",
        "    \n",
        "\n",
        "    # display the predictions with the image\n",
        "    '''\n",
        "    cv2.putText(orig, \"Predicted: {}\".format(label), (10, 30),\n",
        "                cv2.FONT_HERSHEY_PLAIN, 1.5, (43, 99, 255), 2)\n",
        "\n",
        "    cv2.imshow(\"Classification\", orig)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    '''\n",
        "    return output_y,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt5-0TBjWaiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Enter_Required_Data():\n",
        "\n",
        "    Message1 = \"Enter PDF Source Path (End with /,Example: C:/User/Admin/Documents/):\"\n",
        "    Message2 = \"Enter PDF name (Example: Henry.pdf)\"\n",
        "    print(Message1)\n",
        "    pdf_source = input()\n",
        "    print(Message2)\n",
        "    File_Name = input()\n",
        "    return File_Name, pdf_source"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50hs_XmTW8-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Pdf_data_Extractor(File_Name, pdf_source):\n",
        "\n",
        "    Png_conversion_Script = \"/content/drive/My Drive/Splitter\"\n",
        "    Pdf_Source_File_Name = pdf_source + File_Name\n",
        "\n",
        "    reader = PyPDF2.PdfFileReader(Pdf_Source_File_Name)\n",
        "    writer = PyPDF2.PdfFileWriter()\n",
        "\n",
        "    File_Name = File_Name.split('.')[0]\n",
        "    #os.mkdir(pdf_source+\"Temp\")\n",
        "    Total_Number_of_Pages = reader.getNumPages()\n",
        "    for Pg_No in range(0,Total_Number_of_Pages):\n",
        "        Temporary_Directory = pdf_source + \"Temp/\" + File_Name+str(Pg_No)\n",
        "        writer.addPage(reader.getPage(Pg_No))\n",
        "        Command = \"{} -f {} -l {} {} {}\".format(Png_conversion_Script, Pg_No+1, Pg_No+1, Pdf_Source_File_Name, Temporary_Directory)\n",
        "        #os.getcwd()\n",
        "        #os.system(Command)\n",
        "        print(Command)\n",
        "    return writer,Total_Number_of_Pages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPAzpGQ_XNGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_And_Bookmark(writer,Total_Number_of_Pages, source_name, file_name):\n",
        "\n",
        "    CATEGORIES = os.listdir('/content/drive/My Drive/TBird/DOCS/train')\n",
        "    CATEGORIT=[]\n",
        "    for g in range(0, int(13)):\n",
        "        if (g<12):\n",
        "            CATEG =writer.addBookmark(CATEGORIES[g], 0, color=(1,0,0), bold=True)\n",
        "            CATEGORIT.append(CATEG)\n",
        "        else:\n",
        "            PARENT = writer.addBookmark(\"MISC DOCS\", 0,color=(0,0,0), bold=True)\n",
        "\n",
        "    List_of_images = os.listdir(source_name+\"/Temp/\")\n",
        "    List_of_images.sort()\n",
        "    b=0\n",
        "    for Page_No, Img in enumerate(List_of_images):\n",
        "        ###############################################\n",
        "        \"\"\"Prediction Code Here returns pos\"\"\"\n",
        "        b=b+1\n",
        "        print(b)\n",
        "\n",
        "        test_image = Image.open(source_name+\"/Temp/\"+Img)\n",
        "        test_imag =source_name+\"/Temp/\"+Img\n",
        "        print(test_imag)\n",
        "        #test_image = process_img(test_image)\n",
        "        prediction, layb = predict(test_imag)\n",
        "        print(prediction, layb)\n",
        "        pos = -1\n",
        "        count = 0\n",
        "        maximum = max(prediction[0])\n",
        "        print()\n",
        "        print()\n",
        "        for i in range(0, len(prediction[0])):\n",
        "            if maximum == prediction[0][i]:\n",
        "                pos = i\n",
        "                count = count + 1\n",
        "            elif maximum * 0.222 < prediction[0][i]:\n",
        "                count = count + 1\n",
        "        if count > 1:\n",
        "            print(\"Not Found\")\n",
        "\n",
        "            writer.addBookmark(\"Not Found\", Page_No, parent=PARENT)\n",
        "\n",
        "        else:\n",
        "            print(layb)\n",
        "            #print(CATEGORIES[pos])\n",
        "            #writer.addBookmark(CATEGORIES[pos], Page_No, parent=CATEGORIT[pos])\n",
        "            writer.addBookmark(layb, Page_No, parent=CATEGORIT[pos])\n",
        "\n",
        "    sys.setrecursionlimit(2000)\n",
        "    with open(source_name+file_name.split(\".\")[0]+\"ReBookmarked.pdf\",\"wb\") as out:\n",
        "        writer.write(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td3jxLdQck-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Remove_Temp_Files(pdf_source):\n",
        "   for x in os.listdir(pdf_source+\"Temp\"):\n",
        "       os.remove(pdf_source+\"Temp/\"+x)\n",
        "   os.removedirs(pdf_source+\"Temp\")\n",
        "    #os.removedirs(pdf_source+\"Temp\")\n",
        "   print(\"Removed Temp Folder\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2iWYJ-cuzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    File_Name, pdf_source = Enter_Required_Data()\n",
        "    Source_Name = pdf_source + File_Name\n",
        "\n",
        "    writer, Total_Number_of_Pages = Pdf_data_Extractor(File_Name, pdf_source)\n",
        "\n",
        "    prediction_And_Bookmark(writer, Total_Number_of_Pages, pdf_source,File_Name)\n",
        "\n",
        "    #Remove_Temp_Files(pdf_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgU-SMZpc34q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpT1ryw4KRMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the path to your test image below\n",
        "image_path = './data/Document_PNG/validation/Bank Statement/Chase-bank-statement-2.png'\n",
        "predict(image_path)\n",
        "\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmMSbrk3Fywa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# add the path to your test image below\n",
        "image_path = '/content/drive/My Drive/TBird/DOCS/train/1003/BALDWIN1-000002.png'\n",
        "predict(image_path)\n",
        "\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-EONCSOGlaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.4.0."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}